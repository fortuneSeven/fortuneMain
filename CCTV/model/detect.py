import cv2
import numpy as np
import os
import tensorflow as tf
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import (
    TimeDistributed, Dropout, Bidirectional, LSTM,
    Dense, Flatten
)
from tensorflow.keras.applications import MobileNetV2


# === 1ï¸âƒ£ ê²½ë¡œ ì„¤ì • ===
VIDEO_PATH = r"C:\coding\fortuneseven\fortuneMain-1\CCTV\model\V_341.mp4"   # ë¶„ì„í•  ì˜ìƒ
OUTPUT_PATH = r"C:\coding\fortuneseven\fortuneMain-1\CCTV\model\output.mp4"     # ê²°ê³¼ ì˜ìƒ ì €ìž¥ ê²½ë¡œ
CAPTURE_DIR = r"C:\coding\fortuneseven\fortuneMain-1\CCTV\model\violence_captures"  # í­ë ¥ ìº¡ì²˜ ì €ìž¥ í´ë”
os.makedirs(CAPTURE_DIR, exist_ok=True)


# === 2ï¸âƒ£ Feature extractor (MobileNetV2) ===
feature_extractor = MobileNetV2(
    weights='imagenet',
    include_top=False,     # fully connected ì œê±°
    pooling=None,          # (2,2,1280) ê·¸ëŒ€ë¡œ ìœ ì§€
    input_shape=(64, 64, 3)
)
print("âœ… Feature extractor ì¤€ë¹„ ì™„ë£Œ:", feature_extractor.output_shape)

# === 3ï¸âƒ£ Violence Detection Model ===
model = Sequential([
    TimeDistributed(Flatten(), input_shape=(16, 2, 2, 1280), name="time_distributed"),
    Dropout(0.5, name='dropout'),
    TimeDistributed(Flatten(), name='time_distributed_1'),
    Bidirectional(LSTM(32, return_sequences=False), name='bidirectional'),
    Dropout(0.5, name='dropout_1'),
    Dense(256, activation='relu', name='dense'),
    Dropout(0.5, name='dropout_2'),
    Dense(128, activation='relu', name='dense_1'),
    Dropout(0.5, name='dropout_3'),
    Dense(64, activation='relu', name='dense_2'),
    Dropout(0.5, name='dropout_4'),
    Dense(32, activation='relu', name='dense_3'),
    Dropout(0.5, name='dropout_5'),
    Dense(2, activation='softmax', name='dense_4')
])

# === 4ï¸âƒ£ ê°€ì¤‘ì¹˜ ë¡œë“œ ===
model.load_weights(r"C:\coding\fortuneseven\fortuneMain-1\CCTV\model\new_violence_detection_model.weights.h5")
print("âœ… Violence Detection ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ!")

# === 5ï¸âƒ£ ë¶„ì„ íŒŒë¼ë¯¸í„° ===
SEQUENCE_LENGTH = 16
IMG_SIZE = (64, 64)
frame_buffer = []
capture_count = 0
MAX_CAPTURES = 8

# === 6ï¸âƒ£ ë¹„ë””ì˜¤ ë¡œë“œ ===
cap = cv2.VideoCapture(VIDEO_PATH)
if not cap.isOpened():
    raise RuntimeError("âŒ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

fps = cap.get(cv2.CAP_PROP_FPS)
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter(OUTPUT_PATH, fourcc, fps, (width, height))

print("ðŸŽ¥ í­ë ¥ ê°ì§€ ì¤‘... (Që¡œ ì¢…ë£Œ)")

# === 7ï¸âƒ£ í”„ë ˆìž„ ë¶„ì„ ë£¨í”„ ===
while True:
    ret, frame = cap.read()
    if not ret:
        break

    # Resize + Normalize
    resized = cv2.resize(frame, IMG_SIZE)
    resized = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)
    resized = np.expand_dims(resized, axis=0) / 255.0

    # === MobileNetV2 Feature ì¶”ì¶œ ===
    features = feature_extractor.predict(resized, verbose=0)  # (1, 2, 2, 1280)
    features = np.squeeze(features, axis=0)                   # (2, 2, 1280)
    frame_buffer.append(features)

    if len(frame_buffer) > SEQUENCE_LENGTH:
        frame_buffer.pop(0)

    label_text = "Analyzing..."
    color = (255, 255, 0)

    # === 16í”„ë ˆìž„ ë‹¨ìœ„ë¡œ í­ë ¥ íŒë³„ ===
    if len(frame_buffer) == SEQUENCE_LENGTH:
        sequence = np.expand_dims(np.array(frame_buffer, dtype=np.float32), axis=0)  # (1,16,2,2,1280)
        print("ðŸ§© ìž…ë ¥ ì‹œí€€ìŠ¤ shape:", sequence.shape)

        preds = model.predict(sequence, verbose=0)
        pred_label = np.argmax(preds)
        confidence = preds[0][pred_label]

        # === í­ë ¥ ê°ì§€ ===
        if pred_label == 1 and confidence > 0.7:
            label_text = f" VIOLENCE DETECTED ({confidence*100:.1f}%)"
            color = (0, 0, 255)

            if capture_count < MAX_CAPTURES:
                capture_path = os.path.join(CAPTURE_DIR, f"capture_{capture_count+1}.jpg")
                cv2.imwrite(capture_path, frame)
                capture_count += 1
                print(f"ðŸš¨ í­ë ¥ ê°ì§€! ìº¡ì²˜ ì €ìž¥ë¨: {capture_path}")
        else:
            label_text = f" SAFE ({confidence*100:.1f}%)"
            color = (0, 255, 0)

    # === ê²°ê³¼ í‘œì‹œ ë° ì €ìž¥ ===
    cv2.putText(frame, label_text, (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, 3)
    out.write(frame)
    cv2.imshow("Violence Detection Demo", frame)

    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

# === 8ï¸âƒ£ ì¢…ë£Œ ===
cap.release()
out.release()
cv2.destroyAllWindows()

print("âœ… ë¶„ì„ ì™„ë£Œ!")
print(f"ðŸŽžï¸ ê²°ê³¼ ì˜ìƒ ì €ìž¥: {OUTPUT_PATH}")
print(f"ðŸ–¼ï¸ ìº¡ì²˜ ì´ë¯¸ì§€ ì €ìž¥ í´ë”: {CAPTURE_DIR}")